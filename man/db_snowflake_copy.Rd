% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/src-snowflakedb.R
\name{db_snowflake_copy}
\alias{db_snowflake_copy}
\title{Perform a COPY INTO in Snowflake to perform a load or unload operation.}
\usage{
db_snowflake_copy(con, from, to, format_opts = list(), opts = list(),
  max_percent_error = 0, with_metadata = FALSE, from_colnames = NULL)
}
\arguments{
\item{con}{A SnowflakeDBConnection object.}

\item{from}{The source of the data, i.e., what comes after the FROM in the COPY
statement. This can be a table, a subquery, a stage, or a local file.}

\item{to}{The target of the COPY statement as a string. This can be a S3/Azure/local
filesystem location, a table, or a Snowflake stage.}

\item{format_opts}{A list of key-value pairs for the Snowflake COPY file_format options.}
}
\description{
Note that default opts here are different from Snowflake's default opts.
}
\details{
This is to:
1. align with tidyverse conventions, and
2. make this amenable to R-produced files.

Note that if TYPE is not provided,
then if utils$guess_delim(from) returns a delim,
  TYPE is set to 'CSV'.

Details:

FIELD_DELIMITER defaults for
Snowflake: ','
db_snowflake_copy(): utils$guess_delim(from)

NULL_IF defaults for
Snowflake: c('\\N')
db_snowflake_copy(): c('\\N', 'NULL', 'NUL', '<NULL>', '<Null>', '', '.', 'NA')
More vals are considered NULL per R convention.
NOTE WELL: NA is cast to NULL because there is no standard way to indicate NA in Snowflake.

SKIP_HEADER defaults for
Snowflake: 0
db_snowflake_copy(): 1 if format_opts$TYPE='CSV', else do not override Snowflake's default.

TRIM_SPACE defaults for
Snowflake: FALSE
db_snowflake_copy(): TRUE
This follows tidyverse convention.
}
\examples{
\dontrun{
# Connection basics ---------------------------------------------------------
# To connect to a database first create a src:
my_db <- src_snowflakedb(user = "snowman",
                         password = "letitsnow",
                         account = "acme",
                         opts = list(warehouse = "mywh",
                                     db = "mydb",
                                     schema = "public")
# Copy from a local CSV file to a target table in my_db.
db_snowflake_copy(my_db$con, from = "file:///my/directory/foo.csv", to = "target_table", 
format_opts = list(format = 'csv', field_delimiter = ','))
}
# Copy from stage
db_snowflake_copy(
  my_db$con,
  from = '@warehouse.stages.my_s3_bucket_name/and/heres/data.tsv',
  to = 'WAREHOUSE.PUBLIC.FOO'
)
}
